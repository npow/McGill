{
 "metadata": {
  "name": "",
  "signature": "sha256:b3b8dc592e05945c9343e5d752d4c64f59941b5aaa0ed6014054151890f2c2f5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import math\n",
      "import numpy as np\n",
      "from collections import Counter\n",
      "from functools import partial\n",
      "from scipy.special import expit as sigmoid\n",
      "from sklearn.cross_validation import *\n",
      "from sklearn.grid_search import *\n",
      "from sklearn.linear_model import *\n",
      "from sklearn.metrics import *\n",
      "from sklearn.metrics.pairwise import rbf_kernel\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.loadtxt('data/wpbcx.dat')\n",
      "Y = np.loadtxt('data/wpbcy.dat').astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def do_cv(clf, n_folds=5):\n",
      "    #skf = KFold(X.shape[0], n_folds=n_folds)\n",
      "    skf = StratifiedKFold(Y, n_folds=n_folds)\n",
      "    D = { 'train_ll': [], 'train_acc': [], 'test_ll': [], 'test_acc': [] }\n",
      "    for train_indices, test_indices in skf:\n",
      "        X_train, X_test = X[train_indices], X[test_indices]\n",
      "        Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
      "        if isinstance(clf, KLR):\n",
      "            best_sigma = None\n",
      "            sigmas = np.arange(0.1, 2.0, 0.2)\n",
      "            X_train_base, X_train_val, Y_train_base, Y_train_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
      "            for sigma in sigmas:\n",
      "                #print \"trying: \", sigma\n",
      "                cc = KLR(sigma=sigma)\n",
      "                cc.fit(X_train_base, Y_train_base)\n",
      "                probas = cc.predict_proba(X_train_val)\n",
      "                ll = log_loss(Y_train_val, probas) / len(Y_test)\n",
      "                best_sigma = sigmas[np.argmin(ll)]\n",
      "            clf = KLR(sigma=best_sigma)\n",
      "            print \"best sigma: \", best_sigma        \n",
      "        \n",
      "        clf.fit(X_train, Y_train)\n",
      "        test_pred = clf.predict(X_test)\n",
      "        test_pred_proba = clf.predict_proba(X_test)  \n",
      "        train_pred = clf.predict(X_train)\n",
      "        train_pred_proba = clf.predict_proba(X_train)\n",
      "        D['test_ll'].append(log_loss(Y_test, test_pred_proba) / len(Y_test))\n",
      "        D['test_acc'].append(accuracy_score(Y_test, test_pred))\n",
      "        D['train_ll'].append(log_loss(Y_train, train_pred_proba) / len(Y_test))\n",
      "        D['train_acc'].append(accuracy_score(Y_train, train_pred))        \n",
      "\n",
      "    print \"train log_loss (mean/std): %f/%f\" % (np.array(D['train_ll']).mean(), np.array(D['train_ll']).std())\n",
      "    print \"train acc (mean/std): %f/%f\" % (np.array(D['train_acc']).mean(), np.array(D['train_acc']).std())\n",
      "    print \"test log_loss (mean/std): %f/%f\" % (np.array(D['test_ll']).mean(), np.array(D['test_ll']).std())\n",
      "    print \"test acc (mean/std): %f/%f\" % (np.array(D['test_acc']).mean(), np.array(D['test_acc']).std())    \n",
      "    print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GDA:\n",
      "    def __init__(self, full_cov):\n",
      "        self.p = [None, None]\n",
      "        self.mu = [None, None]\n",
      "        self.cov = [None, None]\n",
      "        self.full_cov = full_cov\n",
      "        \n",
      "    def fit(self, X, Y):\n",
      "        if np.unique(Y).shape[0] != 2:\n",
      "            raise \"Only binary classification supported\"\n",
      "        c = Counter(Y)\n",
      "        for k in [0, 1]:\n",
      "            self.p[k] = c[k] / Y.shape[0]\n",
      "            self.mu[k] = X[np.where(Y==k)].mean(axis=0)\n",
      "            self.cov[k] = np.sum([np.dot((X[i,:]-self.mu[k]).reshape(-1, 1), (X[i,:]-self.mu[k]).reshape(1, -1)) for i in np.where(Y==k)[0]], axis=0) / c[k]\n",
      "            if not self.full_cov:\n",
      "                self.cov[k] = np.diag(np.diag(self.cov[k]))\n",
      "                \n",
      "    def predict(self, X):\n",
      "        probas = self.predict_proba(X)\n",
      "        pred = [np.argmax(ps) for ps in probas]\n",
      "        return np.array(pred)\n",
      "\n",
      "    def predict_proba(self, X):\n",
      "        def f(x, k):\n",
      "            d = self.cov[k].shape[0]\n",
      "            A = (x-self.mu[k]).reshape(-1, 1)\n",
      "            B = np.linalg.inv(self.cov[k])\n",
      "            retval = math.exp(-0.5*np.dot(np.dot(A.T, B), A))/(((2*math.pi)**(d/2))*math.sqrt(np.linalg.det(self.cov[k])))\n",
      "            return retval * self.p[k]\n",
      "        pred = []\n",
      "        for x in X:\n",
      "            ps = np.array([f(x, 0), f(x, 1)])\n",
      "            ps /= sum(ps)\n",
      "            pred.append(ps)\n",
      "        return np.array(pred)\n",
      "\n",
      "class KLR:\n",
      "    def __init__(self, kernel=lambda v1, v2, sigma: math.exp(-np.linalg.norm(v1-v2, 2)**2/(2.*sigma**2)), alpha=0.01, epochs=100, sigma=1.0):\n",
      "        self.alpha = alpha\n",
      "        self.K = None\n",
      "        self.kernel = partial(kernel, sigma=sigma)\n",
      "        self.epochs = epochs\n",
      "        self.sigma = sigma\n",
      "        self.W = None\n",
      "        self.bias = None        \n",
      "        \n",
      "    def fit(self, X, Y):\n",
      "        self.K = rbf_kernel(X, X, self.sigma)\n",
      "        self.W = np.zeros(X.shape[0])\n",
      "        self.bias = 0\n",
      "        for e in xrange(self.epochs):\n",
      "            for i in xrange(X.shape[0]):\n",
      "                grad = (Y[i] - sigmoid(np.dot(self.W, self.K[:,i])))\n",
      "                self.W -= self.alpha * grad * self.K[:,i]\n",
      "                #self.bias -= self.alpha * grad      \n",
      "            \n",
      "    def predict(self, X):\n",
      "        X = np.concatenate([X, np.ones((X.shape[0], 1))], axis=1)\n",
      "        probas = self.predict_proba(X)\n",
      "        pred = [np.argmax(ps) for ps in probas]\n",
      "        return np.array(pred)\n",
      "    \n",
      "    def predict_proba(self, X):\n",
      "        X = np.concatenate([X, np.ones((X.shape[0], 1))], axis=1)\n",
      "        probas = []\n",
      "        for j,x in enumerate(X):\n",
      "            k = np.array([self.W[i]*self.kernel(x, X[i]) for i in xrange(len(X))]).sum()\n",
      "            p = sigmoid(k)   \n",
      "            sys.stdout.flush()\n",
      "            probas.append([p, 1-p])\n",
      "        return np.array(probas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"kernelized logistic reg: \"\n",
      "do_cv(KLR(), 5)\n",
      "\n",
      "print \"logistic reg: \"\n",
      "do_cv(LogisticRegression(), 5)\n",
      "\n",
      "print \"GDA, full cov: \"\n",
      "do_cv(GDA(full_cov=True), 5)\n",
      "\n",
      "print \"GDA, diag cov: \"\n",
      "do_cv(GDA(full_cov=False), 5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "kernelized logistic reg: \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best sigma:  0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best sigma:  0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best sigma:  0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best sigma:  0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best sigma:  0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train log_loss (mean/std): 0.030121/0.001073\n",
        "train acc (mean/std): 0.783512/0.002457\n",
        "test log_loss (mean/std): 0.030899/0.006138\n",
        "test acc (mean/std): 0.747429/0.024465\n",
        "\n",
        "logistic reg: \n",
        "train log_loss (mean/std): 0.010765/0.000413\n",
        "train acc (mean/std): 0.814397/0.009275\n",
        "test log_loss (mean/std): 0.014043/0.000692\n",
        "test acc (mean/std): 0.727058/0.048995\n",
        "\n",
        "GDA, full cov: \n",
        "train log_loss (mean/std): 0.000033/0.000056"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train acc (mean/std): 1.000000/0.000000\n",
        "test log_loss (mean/std): 0.199770/0.012131\n",
        "test acc (mean/std): 0.762955/0.007024\n",
        "\n",
        "GDA, diag cov: \n",
        "train log_loss (mean/std): 0.032319/0.002466"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train acc (mean/std): 0.684371/0.022077\n",
        "test log_loss (mean/std): 0.050407/0.015627\n",
        "test acc (mean/std): 0.622193/0.103874\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}