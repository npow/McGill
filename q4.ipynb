{
 "metadata": {
  "name": "",
  "signature": "sha256:4aa293cf9e631783651e5beb7e5450bd4d0649a1b58223a49715b219205b71d4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import math\n",
      "import numpy as np\n",
      "from collections import Counter\n",
      "from scipy.special import expit as sigmoid\n",
      "from sklearn.cross_validation import *\n",
      "from sklearn.linear_model import *\n",
      "from sklearn.metrics import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.loadtxt('data/wpbcx.dat')\n",
      "Y = np.loadtxt('data/wpbcy.dat').astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def do_cv(clf, n_folds=5):\n",
      "    #skf = KFold(X.shape[0], n_folds=n_folds)\n",
      "    skf = StratifiedKFold(Y, n_folds=n_folds)\n",
      "    D = { 'train_ll': [], 'train_acc': [], 'test_ll': [], 'test_acc': [] }\n",
      "    for train_indices, test_indices in skf:\n",
      "        X_train, X_test = X[train_indices], X[test_indices]\n",
      "        Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
      "        clf.fit(X_train, Y_train)\n",
      "        test_pred = clf.predict(X_test)\n",
      "        test_pred_proba = clf.predict_proba(X_test)  \n",
      "        train_pred = clf.predict(X_train)\n",
      "        train_pred_proba = clf.predict_proba(X_train)\n",
      "        D['test_ll'].append(log_loss(Y_test, test_pred_proba))\n",
      "        D['test_acc'].append(accuracy_score(Y_test, test_pred))\n",
      "        D['train_ll'].append(log_loss(Y_train, train_pred_proba))\n",
      "        D['train_acc'].append(accuracy_score(Y_train, train_pred))        \n",
      "\n",
      "    print \"train log_loss (mean/std): %f/%f\" % (np.array(D['train_ll']).mean(), np.array(D['train_ll']).std())\n",
      "    print \"train acc (mean/std): %f/%f\" % (np.array(D['train_acc']).mean(), np.array(D['train_acc']).std())\n",
      "    print \"test log_loss (mean/std): %f/%f\" % (np.array(D['test_ll']).mean(), np.array(D['test_ll']).std())\n",
      "    print \"test acc (mean/std): %f/%f\" % (np.array(D['test_acc']).mean(), np.array(D['test_acc']).std())    \n",
      "    print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GDA:\n",
      "    def __init__(self, full_cov):\n",
      "        self.p = [None, None]\n",
      "        self.mu = [None, None]\n",
      "        self.cov = [None, None]\n",
      "        self.full_cov = full_cov\n",
      "        \n",
      "    def fit(self, X, Y):\n",
      "        if np.unique(Y).shape[0] != 2:\n",
      "            raise \"Only binary classification supported\"\n",
      "        c = Counter(Y)\n",
      "        for k in [0, 1]:\n",
      "            self.p[k] = c[k] / Y.shape[0]\n",
      "            self.mu[k] = X[np.where(Y==k)].mean(axis=0)\n",
      "            self.cov[k] = np.sum([np.dot((X[i,:]-self.mu[k]).reshape(-1, 1), (X[i,:]-self.mu[k]).reshape(1, -1)) for i in np.where(Y==k)[0]], axis=0) / c[k]\n",
      "            if not self.full_cov:\n",
      "                self.cov[k] = np.diag(np.diag(self.cov[k]))\n",
      "                \n",
      "    def predict(self, X):\n",
      "        probas = self.predict_proba(X)\n",
      "        pred = [np.argmax(ps) for ps in probas]\n",
      "        return np.array(pred)\n",
      "\n",
      "    def predict_proba(self, X):\n",
      "        def f(x, k):\n",
      "            d = self.cov[k].shape[0]\n",
      "            A = (x-self.mu[k]).reshape(-1, 1)\n",
      "            B = np.linalg.inv(self.cov[k])\n",
      "            retval = math.exp(-0.5*np.dot(np.dot(A.T, B), A))/(((2*math.pi)**(d/2))*math.sqrt(np.linalg.det(self.cov[k])))\n",
      "            return retval * self.p[k]\n",
      "        pred = []\n",
      "        for x in X:\n",
      "            ps = np.array([f(x, 0), f(x, 1)])\n",
      "            ps /= sum(ps)\n",
      "            pred.append(ps)\n",
      "        return np.array(pred)\n",
      "\n",
      "class KLR:\n",
      "    def __init__(self, k=lambda v1, v2, sigma: exp(-np.linalg.norm(v1-v2, 2)**2/(2.*sigma**2)), alpha=0.1, l=0, epochs=100):\n",
      "        self.alpha = alpha\n",
      "        self.k = k\n",
      "        self.l = l\n",
      "        self.epochs = epochs\n",
      "        self.W = None\n",
      "    \n",
      "    def fit(self, X, Y):\n",
      "        Y = [1 if y == 1 else -1 for y in Y]\n",
      "        self.W = np.zeros(X.shape[1])\n",
      "        for e in xrange(self.epochs):\n",
      "            for i in xrange(X.shape[0]):\n",
      "                grad = np.sum([np.dot(1-sigmoid(Y[i]*np.dot(self.W, X[i])),Y[i]*X[i])])\n",
      "                self.W -= self.alpha * grad\n",
      "            \n",
      "    def predict(self, X):\n",
      "        probas = self.predict_proba(X)\n",
      "        pred = [np.argmax(ps) for ps in probas]\n",
      "        return np.array(pred)\n",
      "    \n",
      "    def predict_proba(self, X):\n",
      "        probas = [[sigmoid(-1 * np.dot(x, self.W)), sigmoid(1 * np.dot(x, self.W))] for x in X]\n",
      "        return np.array(probas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"kernelized logistic reg: \"\n",
      "do_cv(KLR(), 5)\n",
      "\n",
      "print \"logistic reg: \"\n",
      "do_cv(LogisticRegression(), 5)\n",
      "\n",
      "print \"GDA, full cov: \"\n",
      "do_cv(GDA(full_cov=True), 5)\n",
      "\n",
      "print \"GDA, diag cov: \"\n",
      "do_cv(GDA(full_cov=False), 5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "kernelized logistic reg: \n",
        "train log_loss (mean/std): 16.026407/1.240232"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train acc (mean/std): 0.535988/0.035908\n",
        "test log_loss (mean/std): 17.401064/3.277670\n",
        "test acc (mean/std): 0.496188/0.094898\n",
        "\n",
        "logistic reg: \n",
        "train log_loss (mean/std): 0.417398/0.008902\n",
        "train acc (mean/std): 0.814397/0.009275\n",
        "test log_loss (mean/std): 0.544951/0.030132\n",
        "test acc (mean/std): 0.727058/0.048995\n",
        "\n",
        "GDA, full cov: \n",
        "train log_loss (mean/std): 0.001253/0.002137"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train acc (mean/std): 1.000000/0.000000\n",
        "test log_loss (mean/std): 7.753496/0.534866\n",
        "test acc (mean/std): 0.762955/0.007024\n",
        "\n",
        "GDA, diag cov: \n",
        "train log_loss (mean/std): 1.253732/0.094234"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train acc (mean/std): 0.684371/0.022077\n",
        "test log_loss (mean/std): 1.951759/0.587750\n",
        "test acc (mean/std): 0.622193/0.103874\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}